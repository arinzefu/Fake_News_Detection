{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = pd.read_csv('news.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c65ba174277138b0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6630057e62af7375"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f83b535fd94e933"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.drop('Unnamed: 0', axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0ee2c419fc7bcc4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94c5215f178a4d18"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fake_news_counts = data['label'].value_counts()\n",
    "\n",
    "# Plot the counts as a bar chart\n",
    "fake_news_counts.plot.bar()\n",
    "\n",
    "# Add axis labels and title\n",
    "plt.xlabel('Fake News')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Fake News Counts')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a13a78a35b8fe0c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fake_news_counts"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "30d22c456940c77b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a dictionary to map 'Real' and 'Fake' values to 1 and 0\n",
    "mapping = {'REAL': 1, 'FAKE': 0}\n",
    "\n",
    "# Apply mapping to label column\n",
    "cols_to_map = ['label']\n",
    "for col in cols_to_map:\n",
    "    data[col] = data[col].map(mapping)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(data.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "418f10476901a02"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.drop('Unnamed: 0', axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54e084a90b7b728a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertModel"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa696e744a27dc8b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load a pre-trained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1b17133faa8cc8eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    # Combine the title and text into a single input string\n",
    "    input_text = example[\"title\"] + \" \" + example[\"text\"]\n",
    "    \n",
    "    # Tokenize the combined input text\n",
    "    return tokenizer(input_text, padding=\"max_length\", truncation=True, max_length=5000)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5ee83cc0e36d7c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Tokenize the dataset\n",
    "tokenized_dataset = data.map(tokenize_function, batched=True)\n",
    "\n",
    "# Get the input_ids from the tokenized dataset \n",
    "input_ids = [example['input_ids'] for example in tokenized_dataset]\n",
    "\n",
    "# Convert input_ids to PyTorch tensors\n",
    "input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccca9d1beb2830b3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the attention_masks from the tokenized dataset for train, validation, and test sets\n",
    "attention_mask = [example['attention_mask'] for example in tokenized_dataset]\n",
    "\n",
    "# Convert attention_mask to PyTorch tensors\n",
    "attention_mask = torch.tensor(attention_mask, dtype=torch.long)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ab44015f619453"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(input_ids)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "263a05254a2d0818"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(attention_mask)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8540d304db51bc01"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tokenized_dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9cf956e9ec8d8de"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert the datasets to PyTorch tensors\n",
    "dataset = tokenized_dataset.remove_columns([\"text\"], [\"title\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1af74d4e70c9a19"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#split the dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the tokenized dataset\n",
    "train_dataset, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "val_dataset, test_dataset = train_test_split(test_data, test_size=0.5, random_state=42)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d537213065c4d8ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fbb1628fd5fbd92"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
